# -*- coding: utf-8 -*-
"""Linear Regression Using Tensorflow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yhLGCEpZ0FXfKnlVap9P5diB8fl41Vpk

# **Introduction to Linear Regression**
"""

import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""Regression is a frequently used problem now-a-days where we need to predict a certain value which is continous.
we know a simple Linear Regression formula that is : 

### ***Y = mX + b*** 


where, 
***m*** -> The Slope
***b*** -> intercept (or) ***bias***

now using a simple linear regression with the scalar data can be very computational quickly and it may need more computational power. 
so to avoid it we use ****vector**** Representation of the data's.
Hence the equation further reduces to the following:
> ### ***Y = X.W***

where, 
***W*** -> is the weight matrix and it has default ***bias*** in it.  


---
so a simple example of the linear regression is given below.
"""

# Initializing the X (independent variable)
X = np.arange(0, 5, 0.1)
X

a = 1 # here a is our slope (assume)
b = 0 # here b is our intercept or bias (assume)

# The linear Regression equation is initialized and the output is given to the Y
Y = a * X + b 

#Simple Plot of the line.

plt.plot(X, Y)
plt.ylabel('Dependent Variable')
plt.xlabel('Independent Variable')
plt.title('Linear Regression')
plt.show()

"""## **Using Dataset to understand Linear Regression**

So, that now we know how the linear regression works let us jump into some datasets and try to get the real world value as a prediction.

Let us create a class to represent the linear regression. 
Here, ***MyLinearRegression*** class is the initialized. 

***The initializer is nothing but the bias we need to give to the system.***
"""

# Initialize the Linear Regression Class

class MyLinearRegression():

  def __init__(self, initializers = 'random'):      # CONSTRUCTOR (sets m and b values)
    if initializers == 'ones':
      self.var = 1.
    elif initializers =='zeros':
      self.var = 0.
    else:
      self.var = tf.random.uniform(shape=[], minval=0., maxval=1.)  
    
    self.m = tf.Variable(1., shape = tf.TensorShape(None))
    self.b = tf.Variable(self.var, shape= tf.TensorShape(None))
    self.cost = []
  
  # MSE (gives the loss value)
  def mse(self, true, predicted):                   
    return tf.reduce_mean(tf.square(true - predicted))
  
  # Predict (predict the values using the eq (Y = mX + b))
  def predict(self, x):                            
    return tf.reduce_sum(self.m * x, 1) + self.b

  # Update (This function learns and reduces the loss)
  def update(self, X, y, learning_rate = 0.01):
    with tf.GradientTape(persistent=True) as g:
      loss = self.mse(y, self.predict(X))
    
    print(f"Loss: {loss}")
    self.cost.append(loss)

    dy_dm = g.gradient(loss, self.m)
    dy_db = g.gradient(loss, self.b)

    self.m.assign_sub(learning_rate * dy_dm)
    self.b.assign_sub(learning_rate * dy_db)

  # Train (Finally the model is trained with X, y)
  def train(self, X, y, learning_rate = 0.01, epochs=5):
    if len(X.shape) == 1:
      X.tf.reshape(X, [X.shape[0], 1])

    self.m.assign([self.var] * X.shape[-1])

    for i in range(epochs + 1):
      print(f'Epoch: {i}')
      self.update(X, y, learning_rate=learning_rate)
    return (self.m, self.b, self.cost)

"""Now, we finished creating our Regression class we move on to import the dataset and do some preprocessing."""

# Import the Fuel Consumption Dataset
df = pd.read_csv('FuelConsumption.csv')
df.head()

df.info()

df.describe().transpose()

df['CO2EMISSIONS'].head()

"""Let us predict the ***CO2EMISSIONS*** using ***ENGINESIZE***

**Independent Variable (X) => ENGINESIZE**

**Dependent Variabe (y) => CO2EMISSIONS**
"""

train_x = np.asanyarray(df[['ENGINESIZE']])   
train_y = np.asanyarray(df[['CO2EMISSIONS']])
print(train_y.shape)

"""Let us normalize the output for better performance and also split the data to later test the performance of our model."""

X = train_x.copy()
y = train_y.copy()

X = X / X.max()
y = y / y.max()

print(f"After normalizing\nX.max() {X.max()}\ny.max() {y.max()}")

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)

"""Let us ***Train*** the data"""

myLinearRegressor = MyLinearRegression(initializers='ones')
history = myLinearRegressor.train(X_train, y_train, learning_rate = 0.01, epochs = 200)

"""Predict the X_test values"""

m, b = history[0], history[1]
y_pred = m * X_test + b
print(y_pred.shape)
print(f"m\t{m}\nb\t{b}")

"""Visualizing the Loss value and see how the loss value is performed on the course of number of epochs."""

plt.plot(history[2], color = 'orange')
plt.xlabel('Epochs')
plt.ylabel('loss')
plt.title('Loss Plot')
plt.show()

"""Let us Visualize the data and see how it looks for both training and test set"""

plt.scatter(X_train, y_train)
plt.xlabel('Engine Size')
plt.ylabel('CO2 Emission')
plt.title('Training Set')
plt.show()

plt.scatter(X_test, y_test)
plt.xlabel('Engine Size')
plt.ylabel('CO2 Emission')
plt.title('Test Set')
plt.show()

"""Let us Predict the line and visualize the line."""

plt.plot(X_test, y_pred, color = 'red')
plt.xlabel('Engine Size')
plt.ylabel('CO2 Emission')
plt.title('Predicted Line')
plt.show()

"""Finally, plot the graph which shows the data and predictions side by side."""

plt.scatter(X_test, y_test, color = 'green')
plt.plot(X_test, y_pred, color = 'red')
plt.xlabel('Engine Size')
plt.ylabel('CO2 Emission')
plt.title('Prediction and Visualization')
plt.show()

